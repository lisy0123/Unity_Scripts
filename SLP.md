#  단층 퍼셉트론 (SLP)

## 0. 퍼셉트론(perceptron)

1957년, 프랑크 로젠블라트, 인공 신경망 모델

뉴런의 동작과 유사한 모델, 여러 입력 받아서 하나의 출력값을 내는 퍼셉트론 고안

뉴런 입력출력신호가 퍼센트론에서의 입력값과 출력값과 유사

각 입력 값에 가중치를 곱해, 더한 값이 임세값($\theta$)를 넘지 않는다면 0, 넘으면 1을 출력

- $\sum_{i=1}^{n} w_{i} x_{i} \leq \theta$​ => 0 출력

- $\sum_{i=1}^{n} w_{i} x_{i}>\theta$​ => 1 출력

$(w,\theta)$

$w$와 $\theta$: **가중치**

$w$: 입력의 영향력과 관련, 가중치 백터들을 한데 모은 것 (가중치 행렬)

$\theta$​(임계치): 편향값, 편항값들을 한데 모은 것 (편향 백터)

## 1. 회귀 분석

### 단층 퍼셉트론 신경망 구조

- 단층 퍼셉트론: 일련의 퍼센트론 한 줄로 배치

- 입력 벡터 하나로부터 출력 벡터 하나 단번에 얻어내는 가장 기본적인 신경망 구조

- 입력 벡터만 공유, 각자의 가중치 벡터와 편향값에 따라 각자의 방식으로 독립적인 정보 따로따로 생산

- **파라미터(parameter)**

  학습 과정 중에 끊임없이 변경되어 가면서 퍼셉트론의 동작 특성을 결정하는 값들, model parameter

- 퍼셉트론끼리 서로 영향 X

  => 높은 수준의 문제 해결 능력 X

  => 입력을 일차 처리, 그 결과 최종 출력을 생성할 퍼셉트론 열에 제공하는 새로운 퍼셉트론 열들을 신경망에 추가

- 계층(layer): 퍼셉트론 열

- 출력 계층

- 은닉 계층: 출력 계층 앞에서 입력을 처리하여 그 결과를출력 계층에 전달하는 계층

- 입력 계층: 인경 신경망에는 필요 X

- **은닉 계층 없이 출력 계층 하나만으로 구성되는 가장 간단한 신경망**

### 텐서 연산 & 미니배치 활용

- **텐서**

  엄밀하게 정의 어려움, 다차원 숫자 배열 정도로만 이해

  0차원 스칼라, 1차원 벡터, 2차원 행렬, 3차원 이상의 숫자 배열, 모두 텐서

  => 반복문보다 간단, 처리 속도 빠름

- **미니배치(minibatch)**

  데이터 처리 효율 높여줌

  개별 학습 데이터의 특징 무시 X, 특징에 너무 휘둘리지 않음 => 유용

  신경망이 여러 데이터를 한꺼번에 처리

  가중치 벡터: $w=(w_1, ...,w_n)$​

  스칼라 편향: $b$

  입력 벡터: $x=(x_1, ..., x_n)$

  스칼라 출력: $y=x_1w_1+...+w_nw_n+b=xw+b$

  - 벡터의 내적 연산 $xw$ 단번에 계산

- **선형 연산**

  입력 성분의 일차식으로 표현되는 계산 과정

- **비선형 연산**

  일차식으로 나타낼 수 없는 계산 과정

- 반복문 사용 피하고, 텐서 연산 이용해 처리

- **Epopch(에포크, 에폭, 이폭)**

  학습 데이터 전체에 대한 한 차례 처리

- **hyper parameter(하이퍼파라미터)**

  에포크 수나 미니배치 크기처럼 학습 과정에서 변경되지 않으면서 신경망 구조나 학습 결과에 영향을 미치는 고려 요인

  학습 전 미리 정해야함

  학습 결과에 큰 영향 미침 => 잘 조절 필요

### 신경망 세 가지 기본 출력 유형

- 회귀 분석

  특징값 하나를 숫자로 추정하여 출력

- 이진 판단

  예, 아니오 중 하나 출력

- 선택 분류

  몇 가지 후보 항목 중 하나 골라 선택 결과 출력

- 인공지능 알고리즘 출력: 세 가지 반복이나 혼합

### 회귀 분석

- 회귀(regression)

  옛 상태로 돌아감

  통계학: 연속형 변수 사이의 모형을 구한 뒤, 적합도 측정하는 분석 방법

### 전복의 고리 수 추정 문제

